{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../../data/serendipity-sac2018/training.csv')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The dataset train has 9,997,850 rows and 4 columns\nNumber of unqiue userIDs are 104,661 and number of movies are 49,151\n"
    }
   ],
   "source": [
    "print('The dataset train has {:,} rows and {:,} columns'.format(train_data.shape[0],train_data.shape[1]))\n",
    "\n",
    "print('Number of unqiue userIDs are {:,} and number of movies are {:,}'.format(len(train_data['userId'].unique()),\n",
    "                                                                     len(train_data['movieId'].unique())))\n",
    "\n",
    "from datetime import datetime\n",
    "train_data['timestamp'] = train_data['timestamp'].apply(lambda x: datetime.fromtimestamp(x/1000))\n",
    "\n",
    "train_data['year'] = train_data['timestamp'].apply(lambda x: x.year)\n",
    "train_data['month'] = train_data['timestamp'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Filtering the data by year <br>\n",
    "Considering years {2016, 2017 and 2018}**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data will reduce by 80.064 % if we filter for only year 2017\n"
     ]
    }
   ],
   "source": [
    "print('The data will reduce by {} % if we filter for only year 2017'.format(\n",
    "    round(len(train_data[train_data['year'] != 2017])*100/len(train_data),3)))\n",
    "\n",
    "train_filtered = train_data[train_data['year'] == 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filtered data has 1,993,188 ratings from 9,997,850 ratings \n",
      "The movies are reduced to 36,536 from 49,151 and \n",
      "The users have reduced to 19,657 from 104,661\n"
     ]
    }
   ],
   "source": [
    "print('The filtered data has {:,} ratings from {:,} ratings \\nThe movies are reduced to {:,} from {:,} and \\nThe users have reduced to {:,} from {:,}'.format(train_filtered.shape[0], train_data.shape[0],\n",
    "len(train_filtered['movieId'].unique()),len(train_data['movieId'].unique()),\n",
    "len(train_filtered['userId'].unique()),len(train_data['userId'].unique())   ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "UM_matrix = np.matrix(train_filtered.pivot(index='userId', columns='movieId', values='rating'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19657, 36536)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UM_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "UM_matrix_sub = UM_matrix[1:500,1:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0],\n",
       "       [  0,   1],\n",
       "       [  0,   2],\n",
       "       ...,\n",
       "       [498,  11],\n",
       "       [498,  12],\n",
       "       [498,  13]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(np.isnan(UM_matrix_sub)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling using the SVD function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = pd.read_csv('../Intermediate_data/train_subset.csv',index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_filtered = pd.read_csv('../Intermediate_data/filtered_movies_genre.csv',index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = train_subset.merge(movies_filtered, how = 'inner', left_on = 'movieId', right_on = 'movieId' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "UM= train_new.pivot(index='userId', columns='movieId', values='rating')\n",
    "UM_matrix = np.matrix(UM.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0, 3)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "userId_unique = list(train_subset['userId'].unique())\n",
    "movieId_unique = list(train_subset['movieId'].unique())\n",
    "\n",
    "userId_unique.index(127137), movieId_unique.index(71057)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CollabFiltering import SVD as svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,q = svd(UM_matrix,hiddenk = 20, epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "UM_matrix_pred = np.dot(p,q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(UM, UM_pred):\n",
    "\n",
    "    subt = np.subtract(UM,UM_pred)\n",
    "    RMSE = np.sqrt(np.square(subt[~np.isnan(subt)]).mean().mean())\n",
    "\n",
    "    return(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_svd = rmse(UM_matrix,UM_matrix_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.12583421346865"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "RMSE_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_Ids = UM.index\n",
    "movie_Ids = UM.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Int64Index([100032, 100036, 100053, 100057, 100058, 100067, 100076, 100093,\n            100119, 100143,\n            ...\n            206902, 206903, 206905, 206916, 206921, 206948, 206951, 206968,\n            206981, 206984],\n           dtype='int64', name='userId', length=19203)"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "user_Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_predictn_all = {}\n",
    "for i in range(UM_matrix_pred.shape[0]):\n",
    "    \n",
    "    predictn_on_unseen = UM_matrix_pred[i][UM.ix[user_Ids[i]].isna()]\n",
    "    unseen_movies = movie_Ids[UM.ix[user_Ids[i]].isna()]\n",
    "\n",
    "    recommendations = pd.DataFrame({ 'unseen_movies': unseen_movies,\n",
    "                        'prediction' :  predictn_on_unseen})\n",
    "\n",
    "    recommendations = recommendations.sort_values(by='prediction',          ascending=False)\n",
    "    top_20 = recommendations[:20]\n",
    "\n",
    "    top_n_predictn_all[str(user_Ids[i])] = {'unseen_movies':top_20['unseen_movies'].tolist(),'prediction' :  top_20['prediction'].tolist() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'unseen_movies': 2737       6428\n 9989     119218\n 4211      27869\n 6315      72142\n 61          114\n 9353     111778\n 420         940\n 4628      39183\n 1454       3429\n 8987     107410\n 14112    164917\n 107         230\n 9154     109370\n 9773     116797\n 1909       4506\n 931        2176\n 7764      93457\n 8247      99214\n 12015    142424\n 14497    167990\n Name: unseen_movies, dtype: int64, 'prediction': 2737     7.459418\n 9989     6.659542\n 4211     6.632183\n 6315     6.394575\n 61       6.382227\n 9353     6.352705\n 420      6.281009\n 4628     6.280025\n 1454     6.242516\n 8987     6.194366\n 14112    6.180800\n 107      6.155717\n 9154     6.139015\n 9773     6.134705\n 1909     6.122736\n 931      6.121447\n 7764     6.119085\n 8247     6.118456\n 12015    6.118084\n 14497    6.074558\n Name: prediction, dtype: float64}"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "top_n_predictn_all['206903']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json = json.dumps(top_n_predictn_all)\n",
    "f = open(\"../Intermediate_data/top_20_predictn_svd.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## KPI's ( for surprise )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAR(predictions, top_n = 5):\n",
    "\n",
    "    Top_5 = get_top_n(predictions,top_n)\n",
    "    All_recalls = list()\n",
    "    for uid in Top_5.keys():\n",
    "\n",
    "        df = pd.DataFrame(Top_5[uid])\n",
    "        est = [1 if x > 3.5 else 0 for x in df[1] ]\n",
    "        act = [1 if x > 3.5 else 0 for x in df[2] ]\n",
    "        All_recalls.append(recall_score(est,act))\n",
    "        \n",
    "    return(np.average(All_recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAP(predictions, top_n = 5):\n",
    "\n",
    "    Top_5 = get_top_n(predictions,top_n)\n",
    "    All_recalls = list()\n",
    "    for uid in Top_5.keys():\n",
    "\n",
    "        df = pd.DataFrame(Top_5[uid])\n",
    "        est = [1 if x > 3.5 else 0 for x in df[1] ]\n",
    "        act = [1 if x > 3.5 else 0 for x in df[2] ]\n",
    "        All_recalls.append(precision_score(est,act))\n",
    "        \n",
    "    return(np.average(All_recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADCG(predictions, top_n = 5):\n",
    "\n",
    "    Top_5 = get_top_n(predictions,top_n)\n",
    "    All_DCG = list()\n",
    "    for uid in Top_5.keys():\n",
    "        \n",
    "        df = pd.DataFrame(Top_5[uid])\n",
    "        DCG = list()\n",
    "        for i in range(len(df)):\n",
    "            if i ==0:\n",
    "                DCG.append(df[2][i])\n",
    "            else:\n",
    "                DCG.append(df[2][i]/np.log2(i+1))\n",
    "        \n",
    "        \n",
    "        All_DCG.append(sum(DCG))\n",
    "        \n",
    "    return(np.average(All_DCG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top predictions ( for surprise )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_top_n(predictions, n=10):\n",
    "    \n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, r_ui, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est, r_ui))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        # print(user_ratings)\n",
    "        user_ratings = sorted(user_ratings,key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using surprise package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborative Filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset,accuracy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.0, 5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix  = Dataset.load_from_df(train_subset[['userId','movieId','rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "train, test = train_test_split(cf_matrix, test_size= .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "Knn_cf = KNNBasic(sim_options={'user_based':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Computing the msd similarity matrix...\nDone computing similarity matrix.\n"
    }
   ],
   "source": [
    "Knn_cf.fit(train)\n",
    "predictions_knn = Knn_cf.test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RMSE: 0.9057\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9057040030448762"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "accuracy.rmse(predictions_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "top_pred_knn = get_top_n(predictions_knn,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(5618, 4.4125, 4.0)]"
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "top_pred_knn[100032]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}